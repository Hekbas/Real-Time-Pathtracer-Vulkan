#version 460
#extension GL_EXT_ray_tracing : enable
#extension GL_GOOGLE_include_directive : enable
#include "common.glsl"

layout(binding = 0, set = 0) uniform accelerationStructureEXT topLevelAS;
layout(binding = 1, set = 0, rgba32f) uniform image2D outputImage;

// GBuffer bindings
layout(binding = 6, set = 0, rgba32f) uniform image2D gbufferPosition;
layout(binding = 7, set = 0, rgba32f) uniform image2D gbufferNormal;
layout(binding = 8, set = 0, rgba32f) uniform image2D gbufferAlbedo;
layout(binding = 9, set = 0, rg32f) uniform image2D gbufferMotion;

layout(binding = 10, set = 0) uniform MatrixBuffer {
    mat4 view;
    mat4 proj;
    mat4 prevView;
    mat4 prevProj;
} matrices;

layout(push_constant) uniform PushConstants {
    int frame;
    vec3 cameraPos;
} pc;

layout(location = 0) rayPayloadEXT HitPayload payload;

void createCoordinateSystem(in vec3 N, out vec3 T, out vec3 B) {
    if(abs(N.x) > abs(N.y))
        T = vec3(N.z, 0, -N.x) / sqrt(N.x * N.x + N.z * N.z);
    else
        T = vec3(0, -N.z, N.y) / sqrt(N.y * N.y + N.z * N.z);
    B = cross(N, T);
}

vec3 sampleHemisphere(float rand1, float rand2) {
    vec3 dir;
    dir.x = cos(2 * M_PI * rand2) * sqrt(1 - rand1 * rand1);
    dir.y = sin(2 * M_PI * rand2) * sqrt(1 - rand1 * rand1);
    dir.z = rand1;
    return dir;
}

vec3 sampleDirection(float rand1, float rand2, vec3 normal) {
    vec3 tangent;
    vec3 bitangent;
    createCoordinateSystem(normal, tangent, bitangent);
    vec3 dir = sampleHemisphere(rand1, rand2);
    return dir.x * tangent + dir.y * bitangent + dir.z * normal;
}

vec3 worldToScreenSpace(vec3 worldPos, mat4 viewProj) {
    vec4 clipPos = viewProj * vec4(worldPos, 1.0);
    clipPos.xyz /= clipPos.w;
    return clipPos.xyz * 0.5 + 0.5; // Convert to [0, 1] range
}

// Helper function to extract camera vectors from view matrix
vec3 getCameraFront(mat4 viewMatrix) {
    return normalize(vec3(-viewMatrix[0][2], -viewMatrix[1][2], -viewMatrix[2][2]));
}

vec3 getCameraRight(mat4 viewMatrix) {
    return normalize(vec3(viewMatrix[0][0], viewMatrix[1][0], viewMatrix[2][0]));
}

vec3 getCameraUp(mat4 viewMatrix) {
    return normalize(vec3(viewMatrix[0][1], viewMatrix[1][1], viewMatrix[2][1]));
}

void main()
{
    // SPP for anti-aliasing
    int maxSamples = 8;
    vec3 color = vec3(0.0);

    // Extract camera vectors from view matrix
    vec3 cameraFront = getCameraFront(matrices.view);
    vec3 cameraRight = getCameraRight(matrices.view);
    vec3 cameraUp = getCameraUp(matrices.view);

    for(uint sampleNum = 0; sampleNum < maxSamples; sampleNum++) {
        // Unique random seed per sample/frame
        uvec2 s = pcg2d(ivec2(gl_LaunchIDEXT.xy) * (sampleNum + maxSamples * pc.frame + 1));
        uint seed = s.x + s.y;

        // Calc ray + AA Jitter
        const vec2 screenPos = vec2(gl_LaunchIDEXT.xy) + vec2(rand(seed), rand(seed));
        const vec2 inUV = screenPos / vec2(gl_LaunchSizeEXT.xy);
        vec2 d = inUV * 2.0 - 1.0;
        
        float aspect_ratio = float(gl_LaunchSizeEXT.x) / float(gl_LaunchSizeEXT.y);
        float fov = 80.0; 
        float tan_fov = tan(radians(fov * 0.5));

        vec3 rayDir = normalize(
            cameraFront +
            cameraRight * d.x * aspect_ratio * tan_fov +
            cameraUp    * d.y * tan_fov
        );

        // Initial ray properties
        vec4 origin    = vec4(pc.cameraPos, 1.0);
        vec4 direction = vec4(rayDir, 0.0);
        vec3 weight = vec3(12.0);
        payload.done = false;

        // Trace primary ray
        traceRayEXT(topLevelAS, gl_RayFlagsOpaqueEXT, 0xff, 0, 0, 0, origin.xyz, 0.001, direction.xyz, 10000.0, 0);

        // Fill GBuffer with primary hit data (only for first sample)
        if (sampleNum == 0) {
            // Store position (world space)
            imageStore(gbufferPosition, ivec2(gl_LaunchIDEXT.xy), vec4(payload.position, 1.0));
            
            // Store normal (world space)
            imageStore(gbufferNormal, ivec2(gl_LaunchIDEXT.xy), vec4(payload.normal, 1.0));
            
            // Store albedo (linear space)
            imageStore(gbufferAlbedo, ivec2(gl_LaunchIDEXT.xy), vec4(payload.albedo, 1.0));
            
            // Calculate and store motion vectors
            vec4 currentClipPos = matrices.proj * matrices.view * vec4(payload.position, 1.0);
            currentClipPos.xyz /= currentClipPos.w;
            vec2 currentUV = currentClipPos.xy * 0.5 + 0.5;
            
            vec4 prevClipPos = matrices.prevProj * matrices.prevView * vec4(payload.position, 1.0);
            prevClipPos.xyz /= prevClipPos.w;
            vec2 prevUV = prevClipPos.xy * 0.5 + 0.5;
            
            vec2 motion = currentUV - prevUV;
            imageStore(gbufferMotion, ivec2(gl_LaunchIDEXT.xy), vec4(motion, 0.0, 1.0));
        }

        // Add emitted light from hit
        color += weight * payload.emission;

        // Prepare next bounce
        origin.xyz = payload.position;
        direction.xyz = sampleDirection(rand(seed), rand(seed), payload.normal);
        float pdf = 1.0 / (2.0 * M_PI);

        // Update path weight with BDRF...
        weight *= payload.brdf * dot(direction.xyz, payload.normal) / pdf;

        // Terminate ray if weight is too low
        if(payload.done){
            break;
        }
    }
    color /= maxSamples;
    
    // Convert to sRGB for display
    vec3 linearColor = color;
    vec3 srgbColor = pow(linearColor, vec3(1.0/2.2));
    
    vec4 oldColor = imageLoad(outputImage, ivec2(gl_LaunchIDEXT.xy));
    vec4 newColor = (vec4(srgbColor, 1.0) + (oldColor * pc.frame)) / (pc.frame + 1);
    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), newColor);
}